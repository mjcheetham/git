#!/usr/bin/perl
#
# Parse the JSON output generated by `git survey --json` to
# support the actual unit tests in the shell script.

use strict;
use warnings;
use JSON::PP;
use Data::Dumper;

$Data::Dumper::Sortkeys = 1;
$Data::Dumper::Indent = 1;
$Data::Dumper::Purity = 1;
$Data::Dumper::Pair = ':';

my $stdin = join("", <STDIN>);
my $data = decode_json $stdin;

#my $dump = Dumper($data);
#print $dump;

# Create a series of functions / command line args to extract certain
# key values so that the shell script can verify them.
#
# (1) The full JSON data set contains too much data to sanely test in
# a shell script
#
# (2) Some JSON fields are fundamental/foundational, like the number
# of objects, the size of the largest item, or the pathname of the
# largest item.  But others are transient, like whether an object or
# ref is packed or loose.  And then there are some really transient
# values, like the SHAs of commits when we don't control for the
# data/time.  So for simplicity our shell script test will verify the
# basics and not try to do an exact match on the entire data set.
#
# (3) Most of the functionality in `git survey` comes from the various
# existing iterators, for example to enumerate the desired set of refs
# and to treewalk the set of reachable commits, trees, and blobs and
# we are just using iterator callbacks to collect data on the repo.
# We do not need to verify the correctness of the iterator code; we
# just need to verify that we've used it properly when we collected
# our stats.

# Print various '....count' values from the JSON data.
#
# We assume that the JSON looks like:
#
# {
#  ...
#   "refs": {
#     "count": 3545,
#     ...
#   },
#   "commits": {
#     "count": 197615,
#     ...
#   },
#   "trees": {
#     "count": 331409,
#     ...
#   },
#   "blobs": {
#     "count": 191847,
#     ...
#   },
#   ...
# }
#
# And we want to emit:
#
# refs.count:3545
# commits.count:197615
# trees.count:331409
# blobs.count:191847
#
sub Count {
    print "refs.count:$data->{'refs'}->{'count'}\n";
    print "commits.count:$data->{'commits'}->{'count'}\n";
    print "trees.count:$data->{'trees'}->{'count'}\n";
    print "blobs.count:$data->{'blobs'}->{'count'}\n";
}

# We currently do not expose the "commits.dist_by_size.*" histogram
# for testing.  The data is valid, but sensitive to the length of the
# SHAs of the parent commits and root tree and the length of the text
# of the commit message.  This is not very interesting and we'll test
# the histogram construction for the other types of objects.
#
# {
#   ...
#   "commits": {
#     "count": 197615,
#     ...
#     "dist_by_size": {
#       "H1": {
#         "count": 2268,
#         "sum_size": 549925,
#         "sum_disk_size": 388778,
#         "hbin_lower": 16,
#         "hbin_upper": 255
#       },
#       "H2": {
#         "count": 194926,
#         "sum_size": 138557614,
#         "sum_disk_size": 76535965,
#         "hbin_lower": 256,
#         "hbin_upper": 4095
#       },
#       ...
#     },
#     ...
#   },

# We also do not expose the "commits.largest_commits_by_size_bytes"
# array for testing.  This is also sensitive to the length of the SHAs
# and the commit message.  We'll explore the histogram construction in
# other types of objects below.
#
# {
#   ...
#   "commits": {
#     "count": 197615,
#     ...
#     "largest_commits_by_size_bytes": [
#       {
#         "size": 78970,
#         "oid": "0ab955aac3217bdc64a5df6dd747e8a2238f0473",
#         ...
#       },
#       {
#         "size": 25831,
#         "oid": "e74f1e05be5adb88b1d3b282fa500e15b3b04aa7",
#         ...
#       },
#       ...
#     },
#     ...
#   },


# Print details for "Largest Commits by Number of Parents".  This is
# an array sorted in descending order.  For multiple commits with the
# same number of parents, the relative order is undefined.
#
# We assume that the JSON looks like:
#
# {
#   ...
#   "commits": {
#     "count": 197615,
#     ...
#     "largest_commits_by_nr_parents": [
#       {
#         "nr_parents": 10,
#         "oid": "16d7601e176cd53f3c2f02367698d06b85e08879",
#         ...
#       },
#       {
#         "nr_parents": 6,
#         "oid": "d425142e2a045a9dd7879d028ec68bd748df48a3",
#         ...
#       },
#       ...
#     ],
#     ...
#   },
#
# And we want to emit:
#
# commits.mostparents[0].nr_parents:10
# commits.mostparents[1].nr_parents:6
# ...
#
sub CommitsMostParents {
    my $nr_items = scalar @{ $data->{'commits'}->{'largest_commits_by_nr_parents'} };
    if ($nr_items == 0) {
	return 0;
    }
    my @arr = @{ $data->{'commits'}->{'largest_commits_by_nr_parents'} };
    my $k;
    for ($k=0; $k < $nr_items; $k++) {
	print "commits.mostparents[$k].nr_parents:$arr[$k]->{'nr_parents'}\n";
    }
}

# Print details of the "Histogram by Number of Parents" data.
#
# We assume that the JSON looks like:
#
# {
#   ...
#   "commits": {
#     "count": 197615,
#     ...
#     "count_by_nr_parents": {
#       "P00": 13,
#       "P01": 148603,
#       "P02": 48950,
#       "P03": 37,
#       "P04": 7,
#       "P05": 3,
#       "P06": 1,
#       "P10": 1
#     }
#   },
#   ...
# }
#
# And we want to emit:
#
# commits.histparents[P00].count:13
# commits.histparents[P01].count:148603
# ...
#
sub CommitsHistParents {
    my $nr_buckets = keys %{ $data->{'commits'}->{'count_by_nr_parents'} };
    if ($nr_buckets == 0) {
	return 0;
    }
    my %dist = %{ $data->{'commits'}->{'count_by_nr_parents'} };
    foreach my $key ( sort keys %dist ) {
	my $value = $dist{$key};
	print "commits.histparents[$key].count:$value\n";
    }
}

# We currently do not expose the "trees.dist_by_size" histogram for
# testing.  The data is valid, but sensitive to the length of a SHA
# and the filenames in the tree.  That makes it a little trickier to
# test and probably not worth the bother (since we'll test the
# histogram setup code with the "trees.dist_by_nr_entries" and the
# histogram size code in the "blobs.dist_by_size" cases.
#
# {
#   ...
#   "trees": {
#     "count": 331409,
#     ...
#     "dist_by_size": {
#       "H1": {
#         "count": 13349,
#         "sum_size": 1953155,
#         "sum_disk_size": 912044,
#         "hbin_lower": 16,
#         "hbin_upper": 255
#       },
#       "H2": {
#         "count": 52677,
#         "sum_size": 101507410,
#         "sum_disk_size": 6549425,
#         "hbin_lower": 256,
#         "hbin_upper": 4095
#       },
#       ...
#     },
#     ...
#   },
#   ...
# }

# We also do not expose the "trees.largest_trees_by_size" array for
# testing (for the same SHA and filename reasons).  We'll assume that
# the same code is used to build the array of largest blobs.
#
# {
#   ...
#   "trees": {
#     "count": 331409,
#     ...
#     "largest_trees_by_size_bytes": [
#       {
#         "size": 58487,
#         "oid": "140160ee18ed56aeaf5e028c60e01874faa9c12d",
#         "name": "t",
#         ...
#       },
#       {
#         "size": 58487,
#         "oid": "2d5af5733ab1061aae9a7babaabf9064783e3891",
#         "name": "t",
#         ...
#       },
#       ...
#     },
#     ...
#   },
#   ...
# }

# Print details for "Histogram by Number of Entries" for trees.  For
# example, the bucket `Q00` contains the count of the trees that have
# between 0 and 3 files/subdirectories.
#
# We assume that the JSON looks like:
#
# {
#   ...
#   "trees": {
#     "count": 331409,
#     "sum_size": 5376309652,
#     ...
#     "dist_by_nr_entries": {
#       "Q00": {
#         "count": 5798,
#         "sum_size": 480428,
#         "sum_disk_size": 390478,
#         "qbin_lower": 0,
#         "qbin_upper": 3
#       },
#       "Q01": {
#         "count": 15217,
#         "sum_size": 4587357,
#         "sum_disk_size": 1177431,
#         "qbin_lower": 4,
#         "qbin_upper": 15
#       },
#       ...
#       "Q05": {
#         "count": 12965,
#         "sum_size": 714372748,
#         "sum_disk_size": 11298665,
#         "qbin_lower": 1024,
#         "qbin_upper": 4095
#       },
#       ...
#     }
#   },
#   ...
# }
#
# And we want to emit:
#
# trees.histentries.Q00.count:5798
# trees.histentries.Q01.count:15217
# ...
# trees.histentries.Q05.count:12965
# ...
#
sub TreesHistEntries {
    my $nr_buckets = keys %{ $data->{'trees'}->{'dist_by_nr_entries'} };
    if ($nr_buckets == 0) {
	return 0;
    }
    my %dist = %{ $data->{'trees'}->{'dist_by_nr_entries'} };
    foreach my $key ( sort keys %dist ) {
	my $value = $dist{$key};
	print "trees.histentries.$key.count:$value->{'count'}\n";
    }
}    

# Print details for "Largest Trees by Number of Entries".  This is an
# array sorted in descending order.  For multiple trees with the same
# number of entries, the relative order is undefined.
#
# We assume that the JSON looks like:
#
# {
#   ...
#   "trees": {
#     "count": 331409,
#     ...
#     "largest_trees_by_nr_entries": [
#       {
#         "nr_entries": 1148,
#         "oid": "140160ee18ed56aeaf5e028c60e01874faa9c12d",
#         "name": "t",
#         ...
#       },
#       {
#         "nr_entries": 942,
#         "oid": "2d5af5733ab1061aae9a7babaabf9064783e3891",
#         "name": "t",
#         ...
#       },
#       ...
#     ],
#     ...
#   },
#   ...
# }
#
# And we want to emit:
#
# trees.mostentries[0].nr_entries:1148
# trees.mostentries[1].nr_entries:942
# ...
#
sub TreesMostEntries {
    my $nr_items = scalar @{ $data->{'trees'}->{'largest_trees_by_nr_entries'} };
    if ($nr_items == 0) {
	return 0;
    }
    my @arr = @{ $data->{'trees'}->{'largest_trees_by_nr_entries'} };
    my $k;
    for ($k=0; $k < $nr_items; $k++) {
	print "trees.mostentries[$k].nr_entries:$arr[$k]->{'nr_entries'}\n";
    }
}

# Print details for the "Histogram by Size in Bytes" for blobs.
#
# We assume that the JSON looks like:
#
# {
#   ...
#   "blobs": {
#     "count": 191847,
#     ...
#     "dist_by_size": {
#       "H0": {
#         "count": 47,
#         "sum_size": 433,
#         "sum_disk_size": 856,
#         "hbin_lower": 0,
#         "hbin_upper": 15
#       },
#       "H1": {
#         "count": 2045,
#         "sum_size": 224602,
#         "sum_disk_size": 145658,
#         "hbin_lower": 16,
#         "hbin_upper": 255
#       },
#       ...
#     }
#   },
#   ...
# }
#
# And we want to emit:
#
# blobs.histsize.H0.count:47
# blobs.histsize.H1.count:2045
# ...
#
sub BlobsHistSize {
    my $nr_buckets = keys %{ $data->{'blobs'}->{'dist_by_size'} };
    if ($nr_buckets == 0) {
	return 0;
    }
    my %dist = %{ $data->{'blobs'}->{'dist_by_size'} };
    foreach my $key ( sort keys %dist ) {
	my $value = $dist{$key};
	print "blobs.histsize.$key.count:$value->{'count'}\n";
    }
}

# Print details for the "Largest Blobs by Size in Bytes" table.
# This is an array sorted in descending order.  If there are multiple
# blobs with the same size, the relative order is undefined.
#
# We assume that the JSON looks like:
#
# {
#   ...
#   "blobs": {
#     "count": 191847,
#     ...
#     "largest_blobs_by_size_bytes": [
#       {
#         "size": 10577552,
#         "oid": "667824451d9202e721b6d9413ce4c6b7ce58c36e",
#         ...
#       },
#       {
#         "size": 6655520,
#         "oid": "78bcd7f596df79b580e793957928be457a61c3f5",
#         ...
#       },
#       ...
#     ],
#   },
#   ...
# }
#
# And we want to emit:
#
# blobs.largest[0].size:10577552
# blobs.largest[1].size:6655520
# ...
#
sub BlobsLargest {
    my $nr_items = scalar @{ $data->{'blobs'}->{'largest_blobs_by_size_bytes'} };
    if ($nr_items == 0) {
	return 0;
    }
    my @arr = @{ $data->{'blobs'}->{'largest_blobs_by_size_bytes'} };
    my $k;
    for ($k=0; $k < $nr_items; $k++) {
	print "blobs.largest[$k].size:$arr[$k]->{'size'}\n";
    }
}

foreach my $arg_k(@ARGV) {
    if ($arg_k eq 'count') {
	Count;
    }
    elsif ($arg_k eq 'commits.mostparents') {
	CommitsMostParents;
    }
    elsif ($arg_k eq 'commits.histparents') {
	CommitsHistParents;
    }
    elsif ($arg_k eq 'trees.histentries') {
	TreesHistEntries;
    }
    elsif ($arg_k eq 'trees.mostentries') {
	TreesMostEntries;
    }
    elsif ($arg_k eq 'blobs.histsize') {
	BlobsHistSize;
    }
    elsif ($arg_k eq 'blobs.largest') {
	BlobsLargest;
    }
    else {
	print "ERROR: unknown command '$arg_k'\n";
	exit 1;
    }
}
